{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 簡楷恒\n",
    "\n",
    "Student ID: 113062582\n",
    "\n",
    "GitHub ID: 73538884\n",
    "\n",
    "Kaggle name: KaiHengChien\n",
    "\n",
    "Kaggle private scoreboard snapshot: ![Kaggle private scoreboard](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/k910723/DM2024-Lab2-Master/blob/main/DM2024-Lab2-Master.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the cell \"student information\" above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the identification (train/test) and their label (emotion) of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "data_identification = pd.read_csv('Data/data_identification.csv')\n",
    "data_identification_train = data_identification[data_identification['identification'] == 'train']\n",
    "emotion = pd.read_csv('Data/emotion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the dataset of tweets from a JSON file, and merges identification, emotion and tweets data on \"tweet_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867535\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the tweets dataset\n",
    "tweet_id = []\n",
    "text = []\n",
    "\n",
    "with open('Data/tweets_DM.json', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        data_dic = json.loads(line)\n",
    "        tweet_id.append(data_dic['_source']['tweet']['tweet_id'])\n",
    "        text.append(data_dic['_source']['tweet']['text'])\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "     'tweet_id': tweet_id,\n",
    "     'text': text,\n",
    "    }\n",
    ")\n",
    "\n",
    "data = pd.merge(data, data_identification, on='tweet_id', how='left')\n",
    "data = pd.merge(data, emotion, on='tweet_id',how='left')\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into training and testing sets based on the \"identification\" column.\n",
    "\n",
    "Then drops the \"identification\" and \"tweet_id\" columns from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455563\n",
      "411972\n"
     ]
    }
   ],
   "source": [
    "train_data = data[data['identification'] == 'train'].copy()\n",
    "test_data = data[data['identification'] == 'test'].copy()\n",
    "\n",
    "train_data = train_data.drop(columns=['identification', 'tweet_id'])\n",
    "test_data = test_data.drop(columns=['identification', 'tweet_id'])\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms the training and testing data into a `DatasetDict` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'emotion'],\n",
       "        num_rows: 1455563\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'emotion'],\n",
       "        num_rows: 411972\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Transform the data into DatasetDict format\n",
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(train_data, preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(test_data, preserve_index=False),\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment for finetuning a BERT model using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\k9107\\AppData\\Roaming\\Python\\Python39\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, Trainer, TrainingArguments\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# select the GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Use the one hot encoder to encode the emotion labels\n",
    "encoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "encoder = encoder.fit(np.reshape(dataset['train']['emotion'], (-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizes the text data and add the embeddings in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'emotion', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 1455563\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'emotion', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 411972\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer function\n",
    "def tokenize_function(data):\n",
    "    embeddings = tokenizer(data['text'])\n",
    "    data.update(embeddings)\n",
    "    data['label'] = encoder.transform(np.reshape(data['emotion'], (-1, 1)))\n",
    "    return data\n",
    "\n",
    "# Tokenize the dataset\n",
    "# Store the tokenized dataset to disk to save time\n",
    "if not os.path.exists('tokenized_dataset'):\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_dataset.save_to_disk('tokenized_dataset')\n",
    "else:\n",
    "    tokenized_dataset = datasets.load_from_disk('tokenized_dataset')\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the classification model using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\k9107\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "\n",
    "# data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# use the BERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(train_data['emotion'].unique()))\n",
    "# training data is split into training and validation sets\n",
    "split_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "# function to evaluate the performance\n",
    "# evaluate.load() is written outside the function to avoid the overhead of loading the metrics multiple time\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\", average=\"macro\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "\n",
    "    return {**accuracy, **f1_score}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  \n",
    "    per_device_train_batch_size=32,  \n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100000,\n",
    "    save_total_limit=5,  # Only last 5 models are saved. Older ones are deleted.\n",
    "    save_steps=100000,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset['train'],\n",
    "    eval_dataset=split_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9590c854394f908f4f24a4f80657b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3037, 'grad_norm': 0.8294836282730103, 'learning_rate': 4.977099935879821e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2598, 'grad_norm': 0.7039676904678345, 'learning_rate': 4.954199871759641e-05, 'epoch': 0.03}\n",
      "{'loss': 0.2452, 'grad_norm': 0.7792961001396179, 'learning_rate': 4.9312998076394615e-05, 'epoch': 0.04}\n",
      "{'loss': 0.2368, 'grad_norm': 1.6333123445510864, 'learning_rate': 4.908399743519282e-05, 'epoch': 0.05}\n",
      "{'loss': 0.232, 'grad_norm': 0.9491744041442871, 'learning_rate': 4.885499679399103e-05, 'epoch': 0.07}\n",
      "{'loss': 0.2269, 'grad_norm': 0.6999340057373047, 'learning_rate': 4.8625996152789234e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2263, 'grad_norm': 1.2519547939300537, 'learning_rate': 4.839699551158743e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2205, 'grad_norm': 0.557869553565979, 'learning_rate': 4.816799487038564e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2192, 'grad_norm': 1.549872636795044, 'learning_rate': 4.7938994229183846e-05, 'epoch': 0.12}\n",
      "{'loss': 0.2214, 'grad_norm': 0.7243902087211609, 'learning_rate': 4.770999358798205e-05, 'epoch': 0.14}\n",
      "{'loss': 0.218, 'grad_norm': 0.8921665549278259, 'learning_rate': 4.748145094806266e-05, 'epoch': 0.15}\n",
      "{'loss': 0.2169, 'grad_norm': 0.6862406730651855, 'learning_rate': 4.7252450306860865e-05, 'epoch': 0.16}\n",
      "{'loss': 0.2155, 'grad_norm': 0.9605560302734375, 'learning_rate': 4.7023449665659065e-05, 'epoch': 0.18}\n",
      "{'loss': 0.2172, 'grad_norm': 0.7394883632659912, 'learning_rate': 4.679444902445727e-05, 'epoch': 0.19}\n",
      "{'loss': 0.2152, 'grad_norm': 1.4575802087783813, 'learning_rate': 4.656544838325548e-05, 'epoch': 0.21}\n",
      "{'loss': 0.2147, 'grad_norm': 0.8563114404678345, 'learning_rate': 4.6336905743336084e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2136, 'grad_norm': 1.0466145277023315, 'learning_rate': 4.6107905102134284e-05, 'epoch': 0.23}\n",
      "{'loss': 0.213, 'grad_norm': 0.8425331115722656, 'learning_rate': 4.58793624622149e-05, 'epoch': 0.25}\n",
      "{'loss': 0.2107, 'grad_norm': 1.0087960958480835, 'learning_rate': 4.56503618210131e-05, 'epoch': 0.26}\n",
      "{'loss': 0.2113, 'grad_norm': 0.8270735144615173, 'learning_rate': 4.5421361179811303e-05, 'epoch': 0.27}\n",
      "{'loss': 0.2078, 'grad_norm': 0.9520872235298157, 'learning_rate': 4.519236053860951e-05, 'epoch': 0.29}\n",
      "{'loss': 0.2109, 'grad_norm': 1.1866440773010254, 'learning_rate': 4.4963359897407716e-05, 'epoch': 0.3}\n",
      "{'loss': 0.2088, 'grad_norm': 0.6838604807853699, 'learning_rate': 4.473435925620592e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2085, 'grad_norm': 1.0055615901947021, 'learning_rate': 4.450535861500412e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2094, 'grad_norm': 1.895921230316162, 'learning_rate': 4.427635797380233e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2083, 'grad_norm': 0.7203007936477661, 'learning_rate': 4.404735733260053e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2086, 'grad_norm': 0.9812722206115723, 'learning_rate': 4.381881469268114e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2088, 'grad_norm': 0.7055259346961975, 'learning_rate': 4.358981405147934e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2074, 'grad_norm': 0.5792081952095032, 'learning_rate': 4.3360813410277554e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2037, 'grad_norm': 0.8950026035308838, 'learning_rate': 4.313181276907576e-05, 'epoch': 0.41}\n",
      "{'loss': 0.203, 'grad_norm': 0.602596640586853, 'learning_rate': 4.290281212787396e-05, 'epoch': 0.43}\n",
      "{'loss': 0.2057, 'grad_norm': 0.7299771308898926, 'learning_rate': 4.2673811486672166e-05, 'epoch': 0.44}\n",
      "{'loss': 0.2007, 'grad_norm': 0.7946526408195496, 'learning_rate': 4.2444810845470366e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2045, 'grad_norm': 0.7574491500854492, 'learning_rate': 4.221626820555098e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2076, 'grad_norm': 0.8427668213844299, 'learning_rate': 4.198726756434918e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2054, 'grad_norm': 0.8374913930892944, 'learning_rate': 4.1758266923147385e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2012, 'grad_norm': 0.8988019227981567, 'learning_rate': 4.152926628194559e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2031, 'grad_norm': 1.2365447282791138, 'learning_rate': 4.13002656407438e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2036, 'grad_norm': 0.7726252675056458, 'learning_rate': 4.1071264999542004e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2006, 'grad_norm': 1.194748044013977, 'learning_rate': 4.084272235962261e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2024, 'grad_norm': 0.7507057785987854, 'learning_rate': 4.061372171842081e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2011, 'grad_norm': 0.7606180310249329, 'learning_rate': 4.038472107721902e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2011, 'grad_norm': 1.2020275592803955, 'learning_rate': 4.0155720436017224e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2017, 'grad_norm': 0.954473078250885, 'learning_rate': 3.992763579738024e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1994, 'grad_norm': 0.8819671273231506, 'learning_rate': 3.969863515617844e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2001, 'grad_norm': 0.7589027881622314, 'learning_rate': 3.9469634514976644e-05, 'epoch': 0.63}\n",
      "{'loss': 0.199, 'grad_norm': 1.2573407888412476, 'learning_rate': 3.924063387377484e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1981, 'grad_norm': 0.8930785059928894, 'learning_rate': 3.901163323257305e-05, 'epoch': 0.66}\n",
      "{'loss': 0.198, 'grad_norm': 0.9557195901870728, 'learning_rate': 3.878263259137126e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1987, 'grad_norm': 0.7144138813018799, 'learning_rate': 3.855363195016946e-05, 'epoch': 0.69}\n",
      "{'loss': 0.1974, 'grad_norm': 0.9569576382637024, 'learning_rate': 3.832463130896767e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1991, 'grad_norm': 0.7049238681793213, 'learning_rate': 3.809563066776587e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2, 'grad_norm': 0.7859876155853271, 'learning_rate': 3.786708802784648e-05, 'epoch': 0.73}\n",
      "{'loss': 0.199, 'grad_norm': 0.6297738552093506, 'learning_rate': 3.763808738664468e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1982, 'grad_norm': 0.7446014285087585, 'learning_rate': 3.740908674544289e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1993, 'grad_norm': 1.126389503479004, 'learning_rate': 3.7180086104241094e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1978, 'grad_norm': 0.7794170379638672, 'learning_rate': 3.69510854630393e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1957, 'grad_norm': 0.6288871169090271, 'learning_rate': 3.6722084821837507e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1942, 'grad_norm': 0.829059362411499, 'learning_rate': 3.6493084180635706e-05, 'epoch': 0.81}\n",
      "{'loss': 0.1976, 'grad_norm': 0.934912919998169, 'learning_rate': 3.626408353943391e-05, 'epoch': 0.82}\n",
      "{'loss': 0.197, 'grad_norm': 0.8911303281784058, 'learning_rate': 3.603554089951452e-05, 'epoch': 0.84}\n",
      "{'loss': 0.1966, 'grad_norm': 0.8579018115997314, 'learning_rate': 3.5806540258312726e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1963, 'grad_norm': 0.7159293293952942, 'learning_rate': 3.5577539617110925e-05, 'epoch': 0.87}\n",
      "{'loss': 0.1969, 'grad_norm': 0.6193302273750305, 'learning_rate': 3.534853897590913e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1948, 'grad_norm': 0.5837749242782593, 'learning_rate': 3.5119538334707345e-05, 'epoch': 0.89}\n",
      "{'loss': 0.1981, 'grad_norm': 1.0558141469955444, 'learning_rate': 3.4890537693505544e-05, 'epoch': 0.91}\n",
      "{'loss': 0.197, 'grad_norm': 0.8327007293701172, 'learning_rate': 3.466199505358615e-05, 'epoch': 0.92}\n",
      "{'loss': 0.1958, 'grad_norm': 0.8887673616409302, 'learning_rate': 3.443299441238436e-05, 'epoch': 0.93}\n",
      "{'loss': 0.1945, 'grad_norm': 0.8637136816978455, 'learning_rate': 3.4203993771182564e-05, 'epoch': 0.95}\n",
      "{'loss': 0.1931, 'grad_norm': 0.7083404064178467, 'learning_rate': 3.397499312998076e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1929, 'grad_norm': 0.972021222114563, 'learning_rate': 3.374599248877897e-05, 'epoch': 0.98}\n",
      "{'loss': 0.1934, 'grad_norm': 1.09112548828125, 'learning_rate': 3.3516991847577176e-05, 'epoch': 0.99}\n",
      "{'loss': 0.1929, 'grad_norm': 0.8140888214111328, 'learning_rate': 3.328799120637538e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1794, 'grad_norm': 0.8898780941963196, 'learning_rate': 3.305899056517359e-05, 'epoch': 1.02}\n",
      "{'loss': 0.1795, 'grad_norm': 0.8280043005943298, 'learning_rate': 3.2830447925254195e-05, 'epoch': 1.03}\n",
      "{'loss': 0.1771, 'grad_norm': 0.9155542850494385, 'learning_rate': 3.26019052853348e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1783, 'grad_norm': 0.8506221175193787, 'learning_rate': 3.237290464413301e-05, 'epoch': 1.06}\n",
      "{'loss': 0.1768, 'grad_norm': 1.0129609107971191, 'learning_rate': 3.2144362004213616e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1772, 'grad_norm': 0.7269256114959717, 'learning_rate': 3.191536136301182e-05, 'epoch': 1.09}\n",
      "{'loss': 0.1746, 'grad_norm': 0.9123126268386841, 'learning_rate': 3.168636072181002e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1754, 'grad_norm': 0.8206300139427185, 'learning_rate': 3.145736008060823e-05, 'epoch': 1.11}\n",
      "{'loss': 0.1752, 'grad_norm': 1.0141383409500122, 'learning_rate': 3.122835943940643e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1766, 'grad_norm': 0.9886866211891174, 'learning_rate': 3.0999358798204634e-05, 'epoch': 1.14}\n",
      "{'loss': 0.178, 'grad_norm': 0.8222455978393555, 'learning_rate': 3.077035815700284e-05, 'epoch': 1.15}\n",
      "{'loss': 0.1777, 'grad_norm': 0.8924885392189026, 'learning_rate': 3.0541357515801046e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1773, 'grad_norm': 1.1346824169158936, 'learning_rate': 3.0312356874599253e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1761, 'grad_norm': 1.4761574268341064, 'learning_rate': 3.008381423467986e-05, 'epoch': 1.2}\n",
      "{'loss': 0.175, 'grad_norm': 0.8327286243438721, 'learning_rate': 2.9854813593478066e-05, 'epoch': 1.21}\n",
      "{'loss': 0.1739, 'grad_norm': 1.0845012664794922, 'learning_rate': 2.9625812952276265e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1781, 'grad_norm': 1.1433331966400146, 'learning_rate': 2.9396812311074472e-05, 'epoch': 1.24}\n",
      "{'loss': 0.178, 'grad_norm': 0.8877714276313782, 'learning_rate': 2.9167811669872675e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1767, 'grad_norm': 1.2797034978866577, 'learning_rate': 2.893881102867088e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1775, 'grad_norm': 1.4025404453277588, 'learning_rate': 2.8710268388751488e-05, 'epoch': 1.28}\n",
      "{'loss': 0.1761, 'grad_norm': 0.6884371638298035, 'learning_rate': 2.8481267747549694e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1778, 'grad_norm': 1.135622501373291, 'learning_rate': 2.82522671063479e-05, 'epoch': 1.31}\n",
      "{'loss': 0.1764, 'grad_norm': 1.074859380722046, 'learning_rate': 2.8023266465146104e-05, 'epoch': 1.32}\n",
      "{'loss': 0.1752, 'grad_norm': 0.9817371368408203, 'learning_rate': 2.779426582394431e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1776, 'grad_norm': 0.8190270066261292, 'learning_rate': 2.7565265182742513e-05, 'epoch': 1.35}\n",
      "{'loss': 0.1743, 'grad_norm': 0.871849775314331, 'learning_rate': 2.733626454154072e-05, 'epoch': 1.36}\n",
      "{'loss': 0.177, 'grad_norm': 1.1645468473434448, 'learning_rate': 2.7107721901621326e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1775, 'grad_norm': 1.0705229043960571, 'learning_rate': 2.6878721260419532e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1755, 'grad_norm': 1.4060766696929932, 'learning_rate': 2.6649720619217732e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1779, 'grad_norm': 1.4009922742843628, 'learning_rate': 2.6420719978015938e-05, 'epoch': 1.42}\n",
      "{'loss': 0.176, 'grad_norm': 1.30321204662323, 'learning_rate': 2.6192177338096545e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1783, 'grad_norm': 0.9181575775146484, 'learning_rate': 2.5963176696894755e-05, 'epoch': 1.44}\n",
      "{'loss': 0.1746, 'grad_norm': 0.9801337718963623, 'learning_rate': 2.5734176055692954e-05, 'epoch': 1.46}\n",
      "{'loss': 0.1764, 'grad_norm': 0.8126156330108643, 'learning_rate': 2.550517541449116e-05, 'epoch': 1.47}\n",
      "{'loss': 0.1751, 'grad_norm': 1.0175683498382568, 'learning_rate': 2.5276174773289367e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1754, 'grad_norm': 0.9780831336975098, 'learning_rate': 2.504717413208757e-05, 'epoch': 1.5}\n",
      "{'loss': 0.1748, 'grad_norm': 1.0198246240615845, 'learning_rate': 2.4818173490885776e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1755, 'grad_norm': 0.9108314514160156, 'learning_rate': 2.458917284968398e-05, 'epoch': 1.53}\n",
      "{'loss': 0.1783, 'grad_norm': 1.0455318689346313, 'learning_rate': 2.4360172208482185e-05, 'epoch': 1.54}\n",
      "{'loss': 0.1739, 'grad_norm': 1.2481772899627686, 'learning_rate': 2.4131629568562792e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1778, 'grad_norm': 0.9632857441902161, 'learning_rate': 2.3902628927361e-05, 'epoch': 1.57}\n",
      "{'loss': 0.173, 'grad_norm': 1.017005443572998, 'learning_rate': 2.3674086287441606e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1779, 'grad_norm': 0.83784419298172, 'learning_rate': 2.3445085646239812e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1749, 'grad_norm': 1.073362112045288, 'learning_rate': 2.3216085005038015e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1725, 'grad_norm': 1.3961433172225952, 'learning_rate': 2.298708436383622e-05, 'epoch': 1.62}\n",
      "{'loss': 0.1733, 'grad_norm': 0.8800249099731445, 'learning_rate': 2.2758083722634424e-05, 'epoch': 1.64}\n",
      "{'loss': 0.1727, 'grad_norm': 1.2792608737945557, 'learning_rate': 2.2529083081432627e-05, 'epoch': 1.65}\n",
      "{'loss': 0.1741, 'grad_norm': 0.8835240006446838, 'learning_rate': 2.2300540441513237e-05, 'epoch': 1.66}\n",
      "{'loss': 0.1754, 'grad_norm': 0.9744799733161926, 'learning_rate': 2.207153980031144e-05, 'epoch': 1.68}\n",
      "{'loss': 0.1761, 'grad_norm': 0.7746374011039734, 'learning_rate': 2.1842539159109647e-05, 'epoch': 1.69}\n",
      "{'loss': 0.1734, 'grad_norm': 1.2169660329818726, 'learning_rate': 2.1613538517907853e-05, 'epoch': 1.7}\n",
      "{'loss': 0.1755, 'grad_norm': 1.2354683876037598, 'learning_rate': 2.1384537876706056e-05, 'epoch': 1.72}\n",
      "{'loss': 0.1725, 'grad_norm': 1.0663363933563232, 'learning_rate': 2.1155537235504262e-05, 'epoch': 1.73}\n",
      "{'loss': 0.1736, 'grad_norm': 1.017058253288269, 'learning_rate': 2.0926536594302465e-05, 'epoch': 1.74}\n",
      "{'loss': 0.1748, 'grad_norm': 0.8898880481719971, 'learning_rate': 2.0697535953100668e-05, 'epoch': 1.76}\n",
      "{'loss': 0.1725, 'grad_norm': 1.137861728668213, 'learning_rate': 2.046899331318128e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1721, 'grad_norm': 0.993294358253479, 'learning_rate': 2.023999267197948e-05, 'epoch': 1.79}\n",
      "{'loss': 0.1698, 'grad_norm': 1.040523886680603, 'learning_rate': 2.0010992030777688e-05, 'epoch': 1.8}\n",
      "{'loss': 0.1735, 'grad_norm': 1.3605642318725586, 'learning_rate': 1.978199138957589e-05, 'epoch': 1.81}\n",
      "{'loss': 0.1739, 'grad_norm': 1.4679489135742188, 'learning_rate': 1.9552990748374097e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1725, 'grad_norm': 0.9605644941329956, 'learning_rate': 1.9323990107172303e-05, 'epoch': 1.84}\n",
      "{'loss': 0.1735, 'grad_norm': 1.5986584424972534, 'learning_rate': 1.9094989465970506e-05, 'epoch': 1.85}\n",
      "{'loss': 0.1748, 'grad_norm': 0.8442810773849487, 'learning_rate': 1.886598882476871e-05, 'epoch': 1.87}\n",
      "{'loss': 0.1719, 'grad_norm': 1.0538994073867798, 'learning_rate': 1.863790418613172e-05, 'epoch': 1.88}\n",
      "{'loss': 0.1732, 'grad_norm': 1.1020981073379517, 'learning_rate': 1.8408903544929926e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1724, 'grad_norm': 0.8229641914367676, 'learning_rate': 1.8179902903728133e-05, 'epoch': 1.91}\n",
      "{'loss': 0.1745, 'grad_norm': 1.1882658004760742, 'learning_rate': 1.7950902262526336e-05, 'epoch': 1.92}\n",
      "{'loss': 0.1717, 'grad_norm': 1.0620372295379639, 'learning_rate': 1.7721901621324542e-05, 'epoch': 1.94}\n",
      "{'loss': 0.1732, 'grad_norm': 2.2913215160369873, 'learning_rate': 1.7492900980122745e-05, 'epoch': 1.95}\n",
      "{'loss': 0.1754, 'grad_norm': 1.104007363319397, 'learning_rate': 1.7264358340203355e-05, 'epoch': 1.96}\n",
      "{'loss': 0.172, 'grad_norm': 0.9452412128448486, 'learning_rate': 1.7035357699001558e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1717, 'grad_norm': 1.2315315008163452, 'learning_rate': 1.680635705779976e-05, 'epoch': 1.99}\n",
      "{'loss': 0.1613, 'grad_norm': 1.676291823387146, 'learning_rate': 1.6577356416597967e-05, 'epoch': 2.01}\n",
      "{'loss': 0.1482, 'grad_norm': 1.5246230363845825, 'learning_rate': 1.634835577539617e-05, 'epoch': 2.02}\n",
      "{'loss': 0.1464, 'grad_norm': 1.2288060188293457, 'learning_rate': 1.6119355134194377e-05, 'epoch': 2.03}\n",
      "{'loss': 0.145, 'grad_norm': 1.5190365314483643, 'learning_rate': 1.5890354492992583e-05, 'epoch': 2.05}\n",
      "{'loss': 0.1461, 'grad_norm': 1.4159075021743774, 'learning_rate': 1.566181185307319e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1471, 'grad_norm': 1.4555350542068481, 'learning_rate': 1.5432811211871396e-05, 'epoch': 2.07}\n",
      "{'loss': 0.1453, 'grad_norm': 1.1156946420669556, 'learning_rate': 1.5203810570669599e-05, 'epoch': 2.09}\n",
      "{'loss': 0.1469, 'grad_norm': 1.9104856252670288, 'learning_rate': 1.4974809929467804e-05, 'epoch': 2.1}\n",
      "{'loss': 0.145, 'grad_norm': 1.6351792812347412, 'learning_rate': 1.4746267289548412e-05, 'epoch': 2.12}\n",
      "{'loss': 0.146, 'grad_norm': 1.6378467082977295, 'learning_rate': 1.4517266648346617e-05, 'epoch': 2.13}\n",
      "{'loss': 0.1468, 'grad_norm': 0.8978516459465027, 'learning_rate': 1.4288266007144822e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1471, 'grad_norm': 1.2469617128372192, 'learning_rate': 1.4059265365943024e-05, 'epoch': 2.16}\n",
      "{'loss': 0.1469, 'grad_norm': 1.1450797319412231, 'learning_rate': 1.3830264724741229e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1465, 'grad_norm': 1.2716130018234253, 'learning_rate': 1.3601722084821838e-05, 'epoch': 2.18}\n",
      "{'loss': 0.1458, 'grad_norm': 0.9974258542060852, 'learning_rate': 1.3372721443620042e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1466, 'grad_norm': 1.0882301330566406, 'learning_rate': 1.3143720802418247e-05, 'epoch': 2.21}\n",
      "{'loss': 0.1448, 'grad_norm': 2.0891664028167725, 'learning_rate': 1.2914720161216452e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1464, 'grad_norm': 1.8438862562179565, 'learning_rate': 1.2685719520014658e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1466, 'grad_norm': 1.3848716020584106, 'learning_rate': 1.2456718878812863e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1475, 'grad_norm': 2.8650174140930176, 'learning_rate': 1.2227718237611065e-05, 'epoch': 2.27}\n",
      "{'loss': 0.1453, 'grad_norm': 0.8794003129005432, 'learning_rate': 1.199871759640927e-05, 'epoch': 2.28}\n",
      "{'loss': 0.144, 'grad_norm': 1.450392246246338, 'learning_rate': 1.1770632957772281e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1461, 'grad_norm': 1.1202387809753418, 'learning_rate': 1.1541632316570487e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1464, 'grad_norm': 1.73593008518219, 'learning_rate': 1.1312631675368692e-05, 'epoch': 2.32}\n",
      "{'loss': 0.1451, 'grad_norm': 1.9687732458114624, 'learning_rate': 1.1084089035449299e-05, 'epoch': 2.34}\n",
      "{'loss': 0.1459, 'grad_norm': 1.3612664937973022, 'learning_rate': 1.0855088394247505e-05, 'epoch': 2.35}\n",
      "{'loss': 0.1472, 'grad_norm': 1.677717685699463, 'learning_rate': 1.0626087753045708e-05, 'epoch': 2.36}\n",
      "{'loss': 0.1477, 'grad_norm': 2.0831427574157715, 'learning_rate': 1.0397087111843913e-05, 'epoch': 2.38}\n",
      "{'loss': 0.1442, 'grad_norm': 1.4289805889129639, 'learning_rate': 1.0168086470642119e-05, 'epoch': 2.39}\n",
      "{'loss': 0.1466, 'grad_norm': 1.6484135389328003, 'learning_rate': 9.939085829440322e-06, 'epoch': 2.4}\n",
      "{'loss': 0.1456, 'grad_norm': 1.3652623891830444, 'learning_rate': 9.710085188238527e-06, 'epoch': 2.42}\n",
      "{'loss': 0.1457, 'grad_norm': 1.9875917434692383, 'learning_rate': 9.481084547036733e-06, 'epoch': 2.43}\n",
      "{'loss': 0.145, 'grad_norm': 2.789095878601074, 'learning_rate': 9.252083905834936e-06, 'epoch': 2.45}\n",
      "{'loss': 0.1447, 'grad_norm': 1.4598461389541626, 'learning_rate': 9.023541265915545e-06, 'epoch': 2.46}\n",
      "{'loss': 0.1442, 'grad_norm': 1.2236523628234863, 'learning_rate': 8.794540624713749e-06, 'epoch': 2.47}\n",
      "{'loss': 0.1456, 'grad_norm': 1.045181155204773, 'learning_rate': 8.565539983511954e-06, 'epoch': 2.49}\n",
      "{'loss': 0.144, 'grad_norm': 1.9878891706466675, 'learning_rate': 8.33653934231016e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1415, 'grad_norm': 1.627820372581482, 'learning_rate': 8.107538701108363e-06, 'epoch': 2.51}\n",
      "{'loss': 0.1447, 'grad_norm': 1.503391981124878, 'learning_rate': 7.878996061188972e-06, 'epoch': 2.53}\n",
      "{'loss': 0.1442, 'grad_norm': 1.0740952491760254, 'learning_rate': 7.649995419987176e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1438, 'grad_norm': 1.5300990343093872, 'learning_rate': 7.420994778785381e-06, 'epoch': 2.56}\n",
      "{'loss': 0.1445, 'grad_norm': 1.7188094854354858, 'learning_rate': 7.1919941375835855e-06, 'epoch': 2.57}\n",
      "{'loss': 0.1451, 'grad_norm': 1.7213075160980225, 'learning_rate': 6.963451497664193e-06, 'epoch': 2.58}\n",
      "{'loss': 0.1443, 'grad_norm': 1.5644078254699707, 'learning_rate': 6.734450856462399e-06, 'epoch': 2.6}\n",
      "{'loss': 0.1469, 'grad_norm': 1.3054660558700562, 'learning_rate': 6.5054502152606025e-06, 'epoch': 2.61}\n",
      "{'loss': 0.1424, 'grad_norm': 1.4055912494659424, 'learning_rate': 6.276449574058808e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1425, 'grad_norm': 1.6007657051086426, 'learning_rate': 6.047448932857013e-06, 'epoch': 2.64}\n",
      "{'loss': 0.1419, 'grad_norm': 1.4458363056182861, 'learning_rate': 5.818448291655216e-06, 'epoch': 2.65}\n",
      "{'loss': 0.1417, 'grad_norm': 1.2437851428985596, 'learning_rate': 5.589447650453421e-06, 'epoch': 2.67}\n",
      "{'loss': 0.1425, 'grad_norm': 2.525636672973633, 'learning_rate': 5.3604470092516265e-06, 'epoch': 2.68}\n",
      "{'loss': 0.1437, 'grad_norm': 1.9462175369262695, 'learning_rate': 5.1323623706146374e-06, 'epoch': 2.69}\n",
      "{'loss': 0.1426, 'grad_norm': 2.287168264389038, 'learning_rate': 4.903361729412843e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1443, 'grad_norm': 1.3398758172988892, 'learning_rate': 4.6743610882110475e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1441, 'grad_norm': 1.8670274019241333, 'learning_rate': 4.445360447009251e-06, 'epoch': 2.73}\n",
      "{'loss': 0.1465, 'grad_norm': 1.2094534635543823, 'learning_rate': 4.216359805807457e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4bdb08b24a4f00b1a05217ee3e8c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1928524374961853, 'eval_accuracy': 0.6690529107253884, 'eval_f1': 0.5946160881877214, 'eval_runtime': 130.4487, 'eval_samples_per_second': 2231.629, 'eval_steps_per_second': 69.744, 'epoch': 2.75}\n",
      "{'loss': 0.1429, 'grad_norm': 1.399204969406128, 'learning_rate': 3.987359164605661e-06, 'epoch': 2.76}\n",
      "{'loss': 0.1434, 'grad_norm': 1.2433348894119263, 'learning_rate': 3.7583585234038656e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1464, 'grad_norm': 1.63530433177948, 'learning_rate': 3.5293578822020702e-06, 'epoch': 2.79}\n",
      "{'loss': 0.1419, 'grad_norm': 2.370330333709717, 'learning_rate': 3.300357241000275e-06, 'epoch': 2.8}\n",
      "{'loss': 0.141, 'grad_norm': 1.1799120903015137, 'learning_rate': 3.0718146010808835e-06, 'epoch': 2.82}\n",
      "{'loss': 0.1441, 'grad_norm': 1.385223388671875, 'learning_rate': 2.8428139598790877e-06, 'epoch': 2.83}\n",
      "{'loss': 0.1419, 'grad_norm': 1.6509250402450562, 'learning_rate': 2.6138133186772927e-06, 'epoch': 2.84}\n",
      "{'loss': 0.1465, 'grad_norm': 1.9401695728302002, 'learning_rate': 2.385270678757901e-06, 'epoch': 2.86}\n",
      "{'loss': 0.1442, 'grad_norm': 1.3060158491134644, 'learning_rate': 2.156270037556105e-06, 'epoch': 2.87}\n",
      "{'loss': 0.1417, 'grad_norm': 0.9414532780647278, 'learning_rate': 1.9272693963543098e-06, 'epoch': 2.89}\n",
      "{'loss': 0.1407, 'grad_norm': 1.7824695110321045, 'learning_rate': 1.6982687551525146e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1452, 'grad_norm': 1.5126780271530151, 'learning_rate': 1.4692681139507192e-06, 'epoch': 2.91}\n",
      "{'loss': 0.14, 'grad_norm': 1.278840184211731, 'learning_rate': 1.2402674727489236e-06, 'epoch': 2.93}\n",
      "{'loss': 0.1409, 'grad_norm': 1.1663626432418823, 'learning_rate': 1.0112668315471282e-06, 'epoch': 2.94}\n",
      "{'loss': 0.1436, 'grad_norm': 1.5126029253005981, 'learning_rate': 7.827241916277366e-07, 'epoch': 2.95}\n",
      "{'loss': 0.1439, 'grad_norm': 1.4250755310058594, 'learning_rate': 5.537235504259412e-07, 'epoch': 2.97}\n",
      "{'loss': 0.1413, 'grad_norm': 1.2533280849456787, 'learning_rate': 3.2472290922414586e-07, 'epoch': 2.98}\n",
      "{'loss': 0.1422, 'grad_norm': 1.4618189334869385, 'learning_rate': 9.572226802235047e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 6568.3072, 'train_samples_per_second': 531.849, 'train_steps_per_second': 16.621, 'train_loss': 0.17593678468049223, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=109170, training_loss=0.17593678468049223, metrics={'train_runtime': 6568.3072, 'train_samples_per_second': 531.849, 'train_steps_per_second': 16.621, 'total_flos': 9.190203055743763e+16, 'train_loss': 0.17593678468049223, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = trainer.predict(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the CSV file with the predicted emotions for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.375       0.09777832 -8.59375    ... -6.8867188  -7.1757812\n",
      "  -1.0996094 ]\n",
      " [-9.859375   -1.8525391  -9.9140625  ... -8.4609375  -8.71875\n",
      "   1.7412109 ]\n",
      " [-4.7109375  -1.0791016  -3.2480469  ... -2.2167969  -3.9765625\n",
      "  -1.71875   ]\n",
      " ...\n",
      " [-3.8925781  -1.8144531  -3.1289062  ...  0.31689453 -4.0429688\n",
      "  -3.5605469 ]\n",
      " [-5.2382812  -4.7148438  -5.296875   ... -4.796875   -5.2382812\n",
      "  -1.0800781 ]\n",
      " [-1.1923828  -4.3476562  -3.6894531  ...  0.87890625 -4.1953125\n",
      "  -5.8203125 ]]\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Decode the one hot encoded labels back to the original emotion labels\n",
    "print(predictions.predictions)\n",
    "decoded_labels = encoder.inverse_transform(predictions.predictions)\n",
    "\n",
    "# Create a DataFrame with the tweet_id and predicted emotion\n",
    "result_df = pd.DataFrame({\n",
    "    'id': data[data['identification'] == 'test']['tweet_id'],\n",
    "    'emotion': decoded_labels.flatten()\n",
    "})\n",
    "\n",
    "# Save the result as a CSV file\n",
    "result_df.to_csv('predicted_emotions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
